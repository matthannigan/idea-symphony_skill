# Research on Question Quality Dimensions in Brainstorming and Facilitated Dialogue

## Introduction
This research investigates the critical dimensions that define a "good" brainstorming question within professional brainstorming and facilitated dialogue contexts. The objective is to understand how question design influences the effectiveness of ideation, the diversity of responses, and the creativity of outcomes. This document synthesizes findings from established frameworks, academic research, and practitioner guidance to develop a rubric for evaluating brainstorming questions.

## Key Question Quality Dimensions

### 1. Open-ended vs. Closed Question Effectiveness in Ideation

**Open-ended questions** are crucial for fostering divergent thinking and generating a wide array of ideas in brainstorming and ideation contexts. The "How Might We" (HMW) framework, for instance, advocates for questions that are broad enough to encourage numerous creative ideas without suggesting a specific solution [1]. This approach inherently promotes open-endedness, allowing participants to explore diverse solution pathways rather than being constrained to a narrow set of predefined answers.

Conversely, **closed questions**, which typically elicit a 'yes' or 'no' or a very specific piece of information, tend to limit the scope of responses and can stifle creativity. While useful for gathering specific data, they are generally less effective in the initial ideation phases of brainstorming where the goal is to maximize idea generation and exploration.

### 2. The Role of Constraint in Question Design

Question design requires a delicate balance in terms of **constraint**. Questions that are **too broad** can lead to unfocused ideation, where responses lack direction and relevance to the core problem. For example, a question like "How might we redesign the submission-drafting process?" was deemed too broad as it loses sight of the specific problem of checking for mistakes [1]. Such overly broad questions can dilute efforts and make it difficult to converge on actionable insights.

Conversely, questions that are **too narrow** or embed solutions can be overly limiting, restricting the pool of possibilities and hindering creative problem-solving. The Nielsen Norman Group emphasizes avoiding HMW questions that suggest a solution, as this restricts the types of ideas generated [1]. For instance, asking "How might we tell users which form to complete to file their taxes?" is too narrow as it pre-supposes a communication-based solution, overlooking other potential approaches like automatic filing or simplified forms [1].

The optimal approach involves crafting questions that are **broad enough to encourage many creative ideas, yet specific enough to remain focused on the desired outcome or root problem** [1]. This balanced constraint guides ideation without imposing undue limitations, fostering both creativity and relevance.

### 3. How Question Specificity Affects Response Diversity

**Question specificity** plays a direct role in influencing the **diversity of responses** during ideation. Highly specific questions, especially those that embed solutions or are too narrow, tend to restrict the range of possible answers, leading to less diverse outcomes [1]. For instance, a question focused on a particular technical solution will likely yield ideas only within that technical domain, neglecting broader, potentially more innovative solutions.

Conversely, **divergent questions**, characterized by their “data-poor” nature, are designed to maximize response diversity [3]. By presenting scenarios with insufficient information for a single correct answer, these questions compel individuals to make assumptions and explore different paths, naturally leading to a wider range of ideas [3].

### 4. Questions with Embedded Assumptions and Creative Responses

Questions with **embedded assumptions** can significantly impact the creativity and diversity of responses. When a question contains implicit assumptions, it can lead to **fixation**, where participants become stuck on a particular line of thought and fail to explore alternative possibilities [2]. For example, a question like "How can we improve the efficiency of our current software by optimizing its database queries?" assumes that the current software and its database are the only viable solution space, potentially overlooking a complete re-architecture or a different technological approach [2].

To foster creativity, questions should be framed to **challenge existing assumptions** and encourage divergent thinking. The "How Might We" framework directly addresses this by warning against solution-suggesting questions, which are a form of embedded assumption [1]. By avoiding such assumptions, questions can open up a wider range of potential solutions and lead to more innovative outcomes.

### 5. Questions that Invite Analysis vs. Questions that Invite Imagination

The distinction between questions that invite **analysis** versus those that invite **imagination** is crucial in brainstorming and ideation. **Analytical questions** typically have a more defined scope and aim to break down a problem into its constituent parts, often leading to a single or limited set of correct answers based on existing data or logical reasoning. These questions are valuable for problem clarification and evaluation but can be less effective for generating novel ideas.

In contrast, **imaginative questions**, such as the divergent questions described by Byrdseed, are designed to spark creativity and exploration of the unknown [3]. These questions often present hypothetical scenarios or "data-poor" situations where participants must fill in the gaps and make creative leaps. For example, asking "What if Spain had not been defeated when the Armada was destroyed in 1588, and Spain went on to conquer England. What would the world be like today?" invites a far more imaginative and exploratory response than a purely analytical question about the historical event [3].

For effective brainstorming, a combination of both types of questions may be necessary. Imaginative questions can be used to generate a wide range of initial ideas, while analytical questions can then be used to refine, evaluate, and select the most promising concepts.

## Rubric for Evaluating Brainstorming Questions

Based on the identified quality dimensions, the following rubric can be used to evaluate brainstorming questions, particularly in contexts where isolated subagents are generating responses. This rubric aims to guide the design of questions that foster creativity, diversity, and relevance.

| Dimension | Criteria for a Good Question | Poor Question Example | Good Question Example |
|---|---|---|---|
| **Open-endedness** | Encourages a wide range of responses; avoids yes/no or single-answer prompts. | "Should we add a new feature?" | "How might we enhance user engagement with our product?" |
| **Constraint (Balanced)** | Broad enough for diverse ideas, yet focused enough to be relevant to the problem; avoids being too broad or too narrow/solution-prescriptive. | "How might we redesign everything?" (Too broad) <br> "How might we implement a chatbot for customer support?" (Too narrow/solution-prescriptive) | "How might we improve customer satisfaction with our support channels?" [1] |
| **Specificity (Impact on Diversity)** | Specific enough to address a clear problem or insight, but not so specific that it limits response diversity; avoids embedding solutions. | "How might we tell users which form to complete?" [1] | "How might we make users feel confident they are filing their taxes correctly?" [1] |
| **Assumptions (Freedom from)** | Challenges existing assumptions; does not pre-suppose a particular solution or problem framing. | "How can we optimize our existing database queries?" [2] | "What alternative approaches could we take to manage our data efficiently?" [2] |
| **Invitation (Analysis vs. Imagination)** | Primarily invites imaginative thinking and exploration of hypotheticals, especially in early ideation phases; balances with analytical questions for refinement. | "What are the current market trends?" (Purely analytical) | "What if our product could anticipate user needs before they arise?" [3] |
| **Positive Framing** | Phrased positively, focusing on desired outcomes rather than negative aspects or problems to be eliminated. | "How might we reduce customer complaints?" [1] | "How might we increase customer delight?" [1] |

## Conclusion
This research has explored the multifaceted dimensions of question quality in brainstorming and facilitated dialogue, highlighting their critical role in shaping ideation outcomes. The synthesis of findings from the "How Might We" framework, a critical review of Osborn's brainstorming assumptions, and the concept of divergent questions reveals that effective question design is a deliberate process that balances open-endedness with appropriate constraint, avoids embedded assumptions, and strategically invites either analytical or imaginative thinking based on the ideation phase.

The developed rubric provides a structured approach for evaluating brainstorming questions, ensuring they are crafted to maximize creativity, diversity, and relevance, especially in environments with isolated subagents. By adhering to these quality dimensions, facilitators and system designers can significantly enhance the effectiveness of brainstorming sessions, leading to more innovative and actionable solutions.

## References

1.  [Using “How Might We” Questions to Ideate on the Right Problems - NN/G](https://www.nngroup.com/articles/how-might-we-questions/)
2.  [Quality, Conformity, and Conflict: Questioning the Assumptions of Osborn’s Brainstorming Technique](https://docs.lib.purdue.edu/cgi/viewcontent.cgi?article=1093&context=jps)
3.  [Divergent Questions (How To Ask ‘Em) - Byrdseed](https://www.byrdseed.com/divergent-questions/)
